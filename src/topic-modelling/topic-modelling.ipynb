{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('it_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(fname, pos=False):\n",
    "    sent = []\n",
    "    for line in open(fname):\n",
    "        line = line.strip().split()\n",
    "        if not line:\n",
    "            if sent: yield sent\n",
    "            sent = []\n",
    "        else:\n",
    "            if pos:\n",
    "                w,p = line\n",
    "                sent.append((w,p))\n",
    "            else:\n",
    "                w, _ = line\n",
    "                sent.append((w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized\n",
    "# documents = [' '.join(d) for d in read(\"project/data/li_data_dict_ma/train/ita-train.tt\")]\n",
    "documents = list(read(\"project/data/li_data_dict_ma/train/ita-train.tt\"))+list(read(\"project/data/li_data_dict_ma/test/ita.tt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3359"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Per',\n",
       "  'due',\n",
       "  'anni',\n",
       "  'gli',\n",
       "  'uomini',\n",
       "  'di',\n",
       "  'Fiorini',\n",
       "  'si',\n",
       "  'sono',\n",
       "  'rifiutati',\n",
       "  'di',\n",
       "  'fornire',\n",
       "  'informazioni',\n",
       "  'su',\n",
       "  'un',\n",
       "  'conto',\n",
       "  'battezzato',\n",
       "  'Reprival',\n",
       "  '.'],\n",
       " [\"All'\",\n",
       "  'inizio',\n",
       "  'il',\n",
       "  'colpo',\n",
       "  'venne',\n",
       "  'attribuito',\n",
       "  'agli',\n",
       "  'hezbollah',\n",
       "  'filo',\n",
       "  'iraniani',\n",
       "  ',',\n",
       "  'più',\n",
       "  'tardi',\n",
       "  'fu',\n",
       "  'ipotizzata',\n",
       "  'una',\n",
       "  'partecipazione',\n",
       "  'del',\n",
       "  'gruppo',\n",
       "  'di',\n",
       "  'Abu',\n",
       "  'Nidal',\n",
       "  ',',\n",
       "  'il',\n",
       "  'più',\n",
       "  'terribile',\n",
       "  'terrorista',\n",
       "  'palestinese',\n",
       "  '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il Papa condanna la \" sistematica emarginazione \" dell\\' altra metà del cielo in campo culturale , chiede \" pari opportunità \" per tutte , cita la pedagoga Montessori quale ideale portabandiera , e soprattutto esalta \" l\\' ingresso sempre più qualificato delle donne non soltanto come fruitrici , ma anche come protagoniste \" in campo intellettuale .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(documents[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('project/data/stopwords-it.txt', 'r') as f:\n",
    "    stoplist = set(f.read().splitlines()).union(('.','*', ';', ':', '?', '!', ',', '\"',\"'\"))\n",
    "    \n",
    "def preprocess(document):\n",
    "    return [w.lemma_.lower() for w in nlp(' '.join(document)) if w.text.lower() not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-23 11:55:27,722 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-04-23 11:55:27,824 : INFO : built Dictionary(9915 unique tokens: ['battezzare', 'contare', 'fiorini', 'fornire', 'informazione']...) from 3359 documents (total 31910 corpus positions)\n",
      "2018-04-23 11:55:27,825 : INFO : saving Dictionary object under /tmp/ailct.dict, separately None\n",
      "2018-04-23 11:55:27,829 : INFO : saved /tmp/ailct.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9915 unique tokens: ['battezzare', 'contare', 'fiorini', 'fornire', 'informazione']...)\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "texts = [preprocess(d) for d in documents]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/tmp/ailct.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uomini',\n",
       "  'fiorini',\n",
       "  'rifiutato',\n",
       "  'fornire',\n",
       "  'informazione',\n",
       "  'contare',\n",
       "  'battezzare',\n",
       "  'reprival'],\n",
       " ['iniziare',\n",
       "  'colpo',\n",
       "  'venire',\n",
       "  'attribuire',\n",
       "  'hezbollah',\n",
       "  'filare',\n",
       "  'iraniano',\n",
       "  'tardo',\n",
       "  'ipotizzare',\n",
       "  'partecipazione',\n",
       "  'abu',\n",
       "  'nidal',\n",
       "  'terribile',\n",
       "  'terrorista',\n",
       "  'palestinese']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-23 11:56:26,999 : INFO : storing corpus in Matrix Market format to /tmp/ailct.mm\n",
      "2018-04-23 11:56:27,001 : INFO : saving sparse matrix to /tmp/ailct.mm\n",
      "2018-04-23 11:56:27,002 : INFO : PROGRESS: saving document #0\n",
      "2018-04-23 11:56:27,022 : INFO : PROGRESS: saving document #1000\n",
      "2018-04-23 11:56:27,041 : INFO : PROGRESS: saving document #2000\n",
      "2018-04-23 11:56:27,060 : INFO : PROGRESS: saving document #3000\n",
      "2018-04-23 11:56:27,070 : INFO : saved 3359x9915 matrix, density=0.094% (31243/33304485)\n",
      "2018-04-23 11:56:27,071 : INFO : saving MmCorpus index to /tmp/ailct.mm.index\n"
     ]
    }
   ],
   "source": [
    "# convert corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('/tmp/ailct.mm', corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-23 18:16:57,948 : INFO : using serial LSI version on this node\n",
      "2018-04-23 18:16:57,973 : INFO : updating model with new documents\n",
      "2018-04-23 18:16:57,974 : INFO : preparing a new chunk of documents\n",
      "2018-04-23 18:16:58,014 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-04-23 18:16:58,016 : INFO : 1st phase: constructing (9915, 150) action matrix\n",
      "2018-04-23 18:16:58,071 : INFO : orthonormalizing (9915, 150) action matrix\n",
      "2018-04-23 18:16:58,982 : INFO : 2nd phase: running dense svd on (150, 3359) matrix\n",
      "2018-04-23 18:16:59,190 : INFO : computing the final decomposition\n",
      "2018-04-23 18:16:59,207 : INFO : keeping 50 factors (discarding 40.949% of energy spectrum)\n",
      "2018-04-23 18:16:59,231 : INFO : processed documents up to #3359\n",
      "2018-04-23 18:16:59,243 : INFO : topic #0(29.873): 0.658*\")\" + 0.628*\"(\" + 0.255*\"vendere\" + 0.151*\"­\" + 0.055*\"milano\" + 0.048*\"aa\" + 0.037*\"lira\" + 0.036*\"vincono\" + 0.036*\"italia\" + 0.034*\"roma\"\n",
      "2018-04-23 18:16:59,248 : INFO : topic #1(23.318): 0.736*\"­\" + -0.577*\"vendere\" + -0.109*\"aa\" + -0.082*\"vincono\" + -0.055*\"premio\" + -0.055*\"brescia\" + -0.055*\"ab\" + -0.055*\"z\" + -0.051*\"s\" + 0.037*\"italiano\"\n",
      "2018-04-23 18:16:59,254 : INFO : topic #2(22.602): 0.631*\"vendere\" + 0.611*\"­\" + -0.235*\")\" + -0.217*\"(\" + 0.120*\"aa\" + 0.090*\"vincono\" + 0.080*\"roma\" + 0.067*\"milano\" + 0.065*\"s\" + 0.060*\"premio\"\n",
      "2018-04-23 18:16:59,259 : INFO : topic #3(13.818): 0.801*\"azione\" + 0.281*\"lira\" + 0.207*\"1000\" + 0.156*\"contare\" + 0.149*\"300\" + 0.102*\"3\" + 0.081*\"correre\" + 0.079*\"tesoro\" + 0.079*\"credito\" + 0.073*\"100\"\n",
      "2018-04-23 18:16:59,265 : INFO : topic #4(12.889): 0.368*\"potere\" + 0.328*\"venire\" + 0.216*\"volere\" + 0.199*\"donna\" + 0.162*\"presidente\" + 0.151*\"-\" + -0.141*\"­\" + 0.128*\"mayo\" + 0.124*\"mettere\" + 0.122*\"piccolo\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-23 18:17:05,212 : INFO : topic #0(29.873): 0.658*\")\" + 0.628*\"(\" + 0.255*\"vendere\" + 0.151*\"­\" + 0.055*\"milano\" + 0.048*\"aa\" + 0.037*\"lira\" + 0.036*\"vincono\" + 0.036*\"italia\" + 0.034*\"roma\"\n",
      "2018-04-23 18:17:05,217 : INFO : topic #1(23.318): 0.736*\"­\" + -0.577*\"vendere\" + -0.109*\"aa\" + -0.082*\"vincono\" + -0.055*\"premio\" + -0.055*\"brescia\" + -0.055*\"ab\" + -0.055*\"z\" + -0.051*\"s\" + 0.037*\"italiano\"\n",
      "2018-04-23 18:17:05,218 : INFO : topic #2(22.602): 0.631*\"vendere\" + 0.611*\"­\" + -0.235*\")\" + -0.217*\"(\" + 0.120*\"aa\" + 0.090*\"vincono\" + 0.080*\"roma\" + 0.067*\"milano\" + 0.065*\"s\" + 0.060*\"premio\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.658*\")\" + 0.628*\"(\" + 0.255*\"vendere\" + 0.151*\"\\xad\" + 0.055*\"milano\" + 0.048*\"aa\" + 0.037*\"lira\" + 0.036*\"vincono\" + 0.036*\"italia\" + 0.034*\"roma\"'),\n",
       " (1,\n",
       "  '0.736*\"\\xad\" + -0.577*\"vendere\" + -0.109*\"aa\" + -0.082*\"vincono\" + -0.055*\"premio\" + -0.055*\"brescia\" + -0.055*\"ab\" + -0.055*\"z\" + -0.051*\"s\" + 0.037*\"italiano\"'),\n",
       " (2,\n",
       "  '0.631*\"vendere\" + 0.611*\"\\xad\" + -0.235*\")\" + -0.217*\"(\" + 0.120*\"aa\" + 0.090*\"vincono\" + 0.080*\"roma\" + 0.067*\"milano\" + 0.065*\"s\" + 0.060*\"premio\"')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.011844287631525039),\n",
       " (1, 0.014090507347567859),\n",
       " (2, 0.004057747366479785),\n",
       " (3, 0.1626190738562196),\n",
       " (4, 0.05505545361032539),\n",
       " (5, 0.015091807802303285),\n",
       " (6, -0.00409723736441963),\n",
       " (7, -0.027208925802335058),\n",
       " (8, 0.04210765639408623),\n",
       " (9, 0.06149589560729715),\n",
       " (10, -0.026426509291045605),\n",
       " (11, -0.011233020348017642),\n",
       " (12, 0.022549640486397605),\n",
       " (13, -0.044596948996156516),\n",
       " (14, -0.03205768027395545),\n",
       " (15, 0.0018758299089645719),\n",
       " (16, 0.025336527716189678),\n",
       " (17, -0.02251279802264066),\n",
       " (18, 0.01053343725715876),\n",
       " (19, -0.005572405255825803),\n",
       " (20, -0.039577427039776764),\n",
       " (21, 0.04095568785235507),\n",
       " (22, -0.011661881304324934),\n",
       " (23, -0.010452110627907272),\n",
       " (24, -0.04255108506342817),\n",
       " (25, 0.038174715556902994),\n",
       " (26, -0.06145220470087308),\n",
       " (27, -0.013114278096092473),\n",
       " (28, -0.005257142365920267),\n",
       " (29, 0.03439589205167867),\n",
       " (30, 0.0310364664565234),\n",
       " (31, -0.016519188487458827),\n",
       " (32, -0.029797128811958087),\n",
       " (33, 0.026904065916599936),\n",
       " (34, -0.027101048237226387),\n",
       " (35, -0.0341262259641776),\n",
       " (36, -0.026366410530844184),\n",
       " (37, -0.06862481792550548),\n",
       " (38, -0.013304705668480462),\n",
       " (39, -0.012679591381369041),\n",
       " (40, -0.03817409571880116),\n",
       " (41, -0.033349774077924985),\n",
       " (42, 0.10048534331611816),\n",
       " (43, 0.038304067506637035),\n",
       " (44, 0.03933316353714608),\n",
       " (45, 0.04388648373693543),\n",
       " (46, -0.02544455408205157),\n",
       " (47, 0.13743192291501027),\n",
       " (48, 0.007651544060558884),\n",
       " (49, 0.07083721769235787)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save topics to a file for dynet\n",
    "with open(\"topic.train\", 'w') as f:\n",
    "    for i, topic in enumerate(lda[corpus][:3110]):\n",
    "        f.write(str(topic[0][0])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
